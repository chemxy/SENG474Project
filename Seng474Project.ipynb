{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>SENG474 Project</center>\n",
    "### <center>Nero lan,Zhangze Chen,Xingyun Chen</center>\n",
    "<br>\n",
    "\n",
    "## <center>topic:heart disease prediction</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import package and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of row in heart disease dataset:1025\n",
      "Number of attribute in heart disease dataset:13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  sklearn.model_selection import train_test_split #used for split a dataser to train set and test set\n",
    "from sklearn.linear_model import LogisticRegression #it is classifier problem, so we use logisticregression\n",
    "from sklearn import metrics\n",
    "#based on tutorial example, we can also use other classifier, such as decision tree\n",
    "# from sklearn.preprocessing import XX used for preprocessing and normalize data by a simple function\n",
    "dataset = pd.read_csv(\"heart.csv\")\n",
    "n_row = dataset.shape[0]\n",
    "print(\"Number of row in heart disease dataset:\" +str(n_row))\n",
    "n_attribute = dataset.shape[1]-1\n",
    "print(\"Number of attribute in heart disease dataset:\" + str(n_attribute))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalize before data mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO do normalized data\n",
    "##\n",
    "Y = dataset['target'].values #label\n",
    "X = dataset.iloc[:,:-1].values #attribute\n",
    "##function comes from input Encoding slides in SENG474\n",
    "x1 = (X-X.min())/(X.max()-X.min())#preprocessing method 1 将attribute都缩放到0到1 （minmaxscaler）\n",
    "x2 = (X-X.mean())/(X.max()-X.min())#preprocessing method 2 和method1 差不多 缩放到-1 到 1(Maxabsscaler)\n",
    "x3 = (X-X.mean())/X.std() #preprocessing method 3 标准化 z-socre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining\n",
    "# .1 logistic regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use Logistic Regression model first, and find the accuracy with different threshold, then calculated the confusion metirc to evluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression method\n",
    "#这里可以改阈值， threshold\n",
    "def log_regression(X,Y,size_test):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = size_test)#split data to two sets, 80%for tranining 20% for testing\n",
    "    ##logisticRegression可以帮我们把数据正则化 (penalty=l2)\n",
    "    log_model = LogisticRegression(penalty='l2',solver='liblinear',multi_class ='ovr')\n",
    "    log_model.fit(X_train,Y_train)\n",
    "    Y_pred = log_model.predict(X_test)\n",
    "    Y_pred_prob = log_model.predict_proba(X_test)\n",
    "    return X_test, Y_test,Y_pred,Y_pred_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction with normalized data and test size = 0.2\n",
      "when threshold is 0.1, Accurracy: 0.7268292682926829\n",
      "when threshold is 0.2, Accurracy: 0.7463414634146341\n",
      "when threshold is 0.3, Accurracy: 0.7951219512195122\n",
      "when threshold is 0.4, Accurracy: 0.848780487804878\n",
      "when threshold is 0.5, Accurracy: 0.8780487804878049\n",
      "when threshold is 0.6, Accurracy: 0.8536585365853658\n",
      "when threshold is 0.7, Accurracy: 0.8146341463414634\n",
      "when threshold is 0.8, Accurracy: 0.7951219512195122\n",
      "when threshold is 0.9, Accurracy: 0.7170731707317073\n",
      "0.9206167904054825\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction with normalized data and test size = 0.2\")\n",
    "X_test, Y_test,Y_pred,Y_pred_prob = log_regression(X,Y,0.2)\n",
    "threshold = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in threshold:\n",
    "    y_pred_threshold = (Y_pred_prob[:,1]>i).astype(int)\n",
    "    score = metrics.accuracy_score(Y_test,y_pred_threshold)\n",
    "    print(\"when threshold is \"+str(i)+\", Accurracy: \"+ str(score) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for Logistic Regression Classifier\n",
    "### Confusion metrix\n",
    "cofusion metrix is the table describe the performance of a classification model\n",
    "\n",
    "|  total |0  | 1| Predict|\n",
    "|  ----  | ----  | ----|----|\n",
    "| 0 |TN  | FP |\n",
    "| 1  | FN | TP |\n",
    "|Actual| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(Y_test,Y_pred):\n",
    "# evaluation part is based on Alex's slides and sample code\n",
    "    conf_m = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "    TP = conf_m[1, 1]\n",
    "    TN = conf_m[0, 0]\n",
    "    FP = conf_m[0, 1]\n",
    "    FN = conf_m[1, 0]\n",
    "    total_n = TP+TN+FP+FN\n",
    "    print(\"Confusion Matrix Table:\")\n",
    "    print(\"n=\"+ str(total_n)+\"|  0  | 1   Predict\")\n",
    "    print(\"   0 |  \"+ str(TN) + \" | \" + str(FP))\n",
    "    print(\"   1 |  \"+ str(FN) + \" | \" + str(TP))\n",
    "    print(\"Actual\")\n",
    "\n",
    "    mis_classify = 1-metrics.accuracy_score(Y_test,Y_pred)\n",
    "    tpr = TP / float(TP + FN) #Sensitivity\n",
    "    tnr = TN / float(TN + FP) #Specificity\n",
    "    fpr = FP / float(TN + FP) #False postive rate\n",
    "    fnr = TP / float(TP + FP) #Precision\n",
    "    print(\"With Logistic Regression Model:\")\n",
    "    print(\"Misclassification Rate: \" + str(mis_classify))\n",
    "    print(\"Sensitivity:            \" + str(tpr)) \n",
    "    print(\"Specificity:            \" + str(tnr))\n",
    "    print(\"False Postive Rate:     \" + str(fpr))\n",
    "    print(\"Precision:              \" + str(fnr))\n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Table:\n",
      "n=205|  0  | 1   Predict\n",
      "   0 |  85 | 18\n",
      "   1 |  7 | 95\n",
      "Actual\n",
      "With Logistic Regression Model:\n",
      "Misclassification Rate: 0.12195121951219512\n",
      "Sensitivity:            0.9313725490196079\n",
      "Specificity:            0.8252427184466019\n",
      "False Postive Rate:     0.17475728155339806\n",
      "Precision:              0.8407079646017699\n",
      "The AUC value:\n",
      "0.9206167904054825\n"
     ]
    }
   ],
   "source": [
    "# when threshold is 0.5, which is the default, there is the highest accuracy,\n",
    "#so we can directly use Y_pred here, because Y_pred is the prediction with threshold =0.5, the default\n",
    "evaluation(Y_test,Y_pred)\n",
    "print(\"The AUC value:\")\n",
    "print(metrics.roc_auc_score(Y_test,Y_pred_prob[:,1]))#这个method是用来判断binary classification model的好坏的 AUC 值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .2 Decision Tree Classifier\n",
    "\n",
    "when appying Decision tree classifier, the problem of overfitting exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean accuracy of this model:0.8975609756097561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Y = dataset['target'].values #label\n",
    "X = dataset.iloc[:,:-1].values #attribute\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "tree_model = DecisionTreeClassifier(criterion=\"entropy\",max_depth=5)\n",
    "#d_tree 很容易出现overfitting,但是我们的dataset不大，所以再所有的parameter中，我们选择限制max_depth 去解决过度拟合问题\n",
    "tree_model.fit(X_train,Y_train)\n",
    "Y_pred = tree_model.predict(X_test)\n",
    "Y_pred_prob = tree_model.predict_proba(X_test)\n",
    "score = tree_model.score(X_test,Y_test)\n",
    "print(\"the mean accuracy of this model:\"+ str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation for decsion tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Table:\n",
      "n=205|  0  | 1   Predict\n",
      "   0 |  88 | 16\n",
      "   1 |  5 | 96\n",
      "Actual\n",
      "With Logistic Regression Model:\n",
      "Misclassification Rate: 0.10243902439024388\n",
      "Sensitivity:            0.9504950495049505\n",
      "Specificity:            0.8461538461538461\n",
      "False Postive Rate:     0.15384615384615385\n",
      "Precision:              0.8571428571428571\n",
      "0.9581587966488956\n"
     ]
    }
   ],
   "source": [
    "evaluation(Y_test,Y_pred)\n",
    "print(metrics.roc_auc_score(Y_test,Y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
