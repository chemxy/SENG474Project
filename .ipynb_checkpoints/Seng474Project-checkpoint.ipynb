{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>SENG474 Project</center>\n",
    "### <center>Nero lan,Zhangze Chen,Xingyun Chen</center>\n",
    "<br>\n",
    "\n",
    "## <center>topic:heart disease prediction</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import package and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of row in heart disease dataset:1025\n",
      "Number of attribute in heart disease dataset:13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  sklearn.model_selection import train_test_split #used for split a dataser to train set and test set\n",
    "from sklearn.linear_model import LogisticRegression #it is classifier problem, so we use logisticregression\n",
    "from sklearn import metrics\n",
    "#based on tutorial example, we can also use other classifier, such as decision tree\n",
    "# from sklearn.preprocessing import XX used for preprocessing and normalize data by a simple function\n",
    "dataset = pd.read_csv(\"heart.csv\")\n",
    "n_row = dataset.shape[0]\n",
    "print(\"Number of row in heart disease dataset:\" +str(n_row))\n",
    "n_attribute = dataset.shape[1]-1\n",
    "print(\"Number of attribute in heart disease dataset:\" + str(n_attribute))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalize before data mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO do normalized data\n",
    "##\n",
    "Y = dataset['target'].values #label\n",
    "X = dataset.iloc[:,:-1].values #attribute\n",
    "##function comes from input Encoding slides in SENG474\n",
    "x1 = (X-X.min())/(X.max()-X.min())#preprocessing method 1 将attribute都缩放到0到1 （minmaxscaler）\n",
    "x2 = (X-X.mean())/(X.max()-X.min())#preprocessing method 2 和method1 差不多 缩放到-1 到 1(Maxabsscaler)\n",
    "x3 = (X-X.mean())/X.std() #preprocessing method 3 标准化 z-socre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression method\n",
    "def log_regression(X,Y,size_test):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = size_test)#split data to two sets, 80%for tranining 20% for testing\n",
    "    ##logisticRegression可以帮我们把数据正则化 (penalty=l2)\n",
    "    log_model = LogisticRegression(penalty='l2',solver='liblinear',multi_class ='ovr')\n",
    "    log_model.fit(X_train,Y_train)\n",
    "    Y_pred = log_model.predict(X_test)\n",
    "    score = log_model.score(X_test,Y_test)\n",
    "    return X_test, Y_test,Y_pred,score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction with normalized data and test size = 0.2\n",
      "Accurracy: 0.8829268292682927\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction with normalized data and test size = 0.2\")\n",
    "X_test, Y_test,Y_pred,score = log_regression(X,Y,0.2)\n",
    "print(\"Accurracy: \"+ str(score) ) ##roger 你自己去看下score()的documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "## Confusion metrix\n",
    "cofusion metrix is the table describe the performance of a classification model\n",
    "\n",
    "|  total |0  | 1| Predict|\n",
    "|  ----  | ----  | ----|----|\n",
    "| 0 |TN  | FP |\n",
    "| 1  | FN | TP |\n",
    "|Actual| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(Y_test,Y_pred):\n",
    "# evaluation part is based on Alex's slides and sample code\n",
    "    conf_m = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "    TP = conf_m[1, 1]\n",
    "    TN = conf_m[0, 0]\n",
    "    FP = conf_m[0, 1]\n",
    "    FN = conf_m[1, 0]\n",
    "    total_n = TP+TN+FP+FN\n",
    "    print(\"Confusion Matrix Table:\")\n",
    "    print(\"n=\"+ str(total_n)+\"|  0  | 1   Predict\")\n",
    "    print(\"   0 |  \"+ str(TN) + \" | \" + str(FP))\n",
    "    print(\"   1 |  \"+ str(FN) + \" | \" + str(TP))\n",
    "    print(\"Actual\")\n",
    "\n",
    "    mis_classify = 1-metrics.accuracy_score(Y_test,Y_pred)\n",
    "    tpr = TP / float(TP + FN) #Sensitivity\n",
    "    tnr = TN / float(TN + FP) #Specificity\n",
    "    fpr = FP / float(TN + FP) #False postive rate\n",
    "    fnr = TP / float(TP + FP) #Precision\n",
    "    print(\"With Logistic Regression Model:\")\n",
    "    print(\"Misclassification Rate: \" + str(mis_classify))\n",
    "    print(\"Sensitivity:            \" + str(tpr)) \n",
    "    print(\"Specificity:            \" + str(tnr))\n",
    "    print(\"False Postive Rate:     \" + str(fpr))\n",
    "    print(\"Precision:              \" + str(fnr))\n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Table:\n",
      "n=205|  0  | 1   Predict\n",
      "   0 |  70 | 20\n",
      "   1 |  4 | 111\n",
      "Actual\n",
      "With Logistic Regression Model:\n",
      "Misclassification Rate: 0.11707317073170731\n",
      "Sensitivity:            0.9652173913043478\n",
      "Specificity:            0.7777777777777778\n",
      "False Postive Rate:     0.2222222222222222\n",
      "Precision:              0.8473282442748091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
